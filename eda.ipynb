{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution visualization\n",
    "- Missing value analysis\n",
    "- Correlation analysis with automatic selection of correlation method\n",
    "- Smart normalization based on outlier presence\n",
    "- Outlier visualization\n",
    "- Comprehensive summary report generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniversalEDA:\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initialize the EDA class with a DataFrame\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            DataFrame to analyze\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "        \n",
    "    def plot_distributions(self, figsize=(15, 5*len(self.numeric_columns))):\n",
    "        \"\"\"\n",
    "        Visualize the distribution of numerical variables\n",
    "        - Histogram\n",
    "        - Box plot\n",
    "        - Q-Q plot for normality check\n",
    "        \"\"\"\n",
    "        n_cols = len(self.numeric_columns)\n",
    "        \n",
    "        fig, axes = plt.subplots(n_cols, 3, figsize=figsize)\n",
    "        \n",
    "        for idx, col in enumerate(self.numeric_columns):\n",
    "            # Histogram\n",
    "            sns.histplot(data=self.df, x=col, ax=axes[idx, 0])\n",
    "            axes[idx, 0].set_title(f'{col} Distribution')\n",
    "            \n",
    "            # Box plot\n",
    "            sns.boxplot(data=self.df, y=col, ax=axes[idx, 1])\n",
    "            axes[idx, 1].set_title(f'{col} Boxplot')\n",
    "            \n",
    "            # Q-Q plot\n",
    "            stats.probplot(self.df[col].dropna(), dist=\"norm\", plot=axes[idx, 2])\n",
    "            axes[idx, 2].set_title(f'{col} Q-Q Plot')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def check_missing_values(self):\n",
    "        \"\"\"\n",
    "        Analyze missing values\n",
    "        - Count and percentage of missing values for each variable\n",
    "        - Return rows containing missing values\n",
    "        \"\"\"\n",
    "        missing_count = self.df.isnull().sum()\n",
    "        missing_percent = (missing_count / len(self.df)) * 100\n",
    "        missing_summary = pd.DataFrame({\n",
    "            'Missing Count': missing_count,\n",
    "            'Missing Percent': missing_percent\n",
    "        }).sort_values('Missing Count', ascending=False)\n",
    "        \n",
    "        print(\"\\n=== Missing Value Summary ===\")\n",
    "        print(missing_summary[missing_summary['Missing Count'] > 0])\n",
    "        \n",
    "        print(\"\\n=== Rows with Missing Values ===\")\n",
    "        return self.df[self.df.isnull().any(axis=1)]\n",
    "    \n",
    "    def correlation_analysis(self):\n",
    "        \"\"\"\n",
    "        Analyze correlations between variables\n",
    "        - Use Pearson or Spearman correlation based on normality test\n",
    "        \"\"\"\n",
    "        correlation_matrix = pd.DataFrame(index=self.numeric_columns, columns=self.numeric_columns)\n",
    "        method_matrix = pd.DataFrame(index=self.numeric_columns, columns=self.numeric_columns)\n",
    "        \n",
    "        for col1 in self.numeric_columns:\n",
    "            for col2 in self.numeric_columns:\n",
    "                # Shapiro-Wilk test for normality\n",
    "                _, p_val1 = stats.shapiro(self.df[col1].dropna())\n",
    "                _, p_val2 = stats.shapiro(self.df[col2].dropna())\n",
    "                \n",
    "                # If both variables are normally distributed (p > 0.05), use Pearson\n",
    "                if p_val1 > 0.05 and p_val2 > 0.05:\n",
    "                    corr, _ = stats.pearsonr(self.df[col1].dropna(), self.df[col2].dropna())\n",
    "                    method = 'Pearson'\n",
    "                else:\n",
    "                    corr, _ = stats.spearmanr(self.df[col1].dropna(), self.df[col2].dropna())\n",
    "                    method = 'Spearman'\n",
    "                \n",
    "                correlation_matrix.loc[col1, col2] = corr\n",
    "                method_matrix.loc[col1, col2] = method\n",
    "        \n",
    "        # Plot correlation heatmap\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "        plt.title('Correlation Matrix')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n=== Correlation Method Used ===\")\n",
    "        print(method_matrix)\n",
    "        \n",
    "        return correlation_matrix, method_matrix\n",
    "    \n",
    "    def normalize_data(self, columns=None):\n",
    "        \"\"\"\n",
    "        Normalize data using appropriate scaling method\n",
    "        - RobustScaler for data with outliers\n",
    "        - StandardScaler for data without outliers\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        columns : list\n",
    "            List of columns to normalize (None for all numeric variables)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        normalized_df : pandas.DataFrame\n",
    "            Normalized DataFrame\n",
    "        scalers : dict\n",
    "            Dictionary of scaler objects used for each column\n",
    "        \"\"\"\n",
    "        if columns is None:\n",
    "            columns = self.numeric_columns\n",
    "            \n",
    "        normalized_df = self.df.copy()\n",
    "        scalers = {}\n",
    "        \n",
    "        for col in columns:\n",
    "            # Check outliers using IQR method\n",
    "            Q1 = self.df[col].quantile(0.25)\n",
    "            Q3 = self.df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outlier_range = 1.5 * IQR\n",
    "            outliers = ((self.df[col] < (Q1 - outlier_range)) | \n",
    "                       (self.df[col] > (Q3 + outlier_range))).sum()\n",
    "            \n",
    "            # Use RobustScaler if outliers are more than 1% of data\n",
    "            if outliers / len(self.df) >= 0.01:\n",
    "                scaler = RobustScaler()\n",
    "                print(f\"{col}: Using RobustScaler (Found {outliers} outliers)\")\n",
    "            else:\n",
    "                scaler = StandardScaler()\n",
    "                print(f\"{col}: Using StandardScaler\")\n",
    "            \n",
    "            normalized_df[col] = scaler.fit_transform(self.df[[col]])\n",
    "            scalers[col] = scaler\n",
    "        \n",
    "        return normalized_df, scalers\n",
    "    \n",
    "    def plot_outliers(self, columns=None):\n",
    "        \"\"\"\n",
    "        Visualize outliers using box plots\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        columns : list\n",
    "            List of columns to visualize (None for all numeric variables)\n",
    "        \"\"\"\n",
    "        if columns is None:\n",
    "            columns = self.numeric_columns\n",
    "            \n",
    "        n_cols = len(columns)\n",
    "        fig, axes = plt.subplots(n_cols, 1, figsize=(10, 5*n_cols))\n",
    "        if n_cols == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        for idx, col in enumerate(columns):\n",
    "            # Calculate outlier bounds\n",
    "            Q1 = self.df[col].quantile(0.25)\n",
    "            Q3 = self.df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # Create boxplot\n",
    "            sns.boxplot(data=self.df, y=col, ax=axes[idx])\n",
    "            \n",
    "            # Add text with outlier information\n",
    "            outliers = ((self.df[col] < lower_bound) | (self.df[col] > upper_bound)).sum()\n",
    "            axes[idx].set_title(f'{col} Outliers: {outliers} points')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n",
    "    def generate_summary_report(self):\n",
    "        \"\"\"\n",
    "        Generate comprehensive data summary report\n",
    "        - Basic information\n",
    "        - Numeric summary\n",
    "        - Missing values analysis\n",
    "        - Distribution plots\n",
    "        - Correlation analysis\n",
    "        - Outlier visualization\n",
    "        \"\"\"\n",
    "        print(\"=== Data Summary Report ===\")\n",
    "        print(\"\\nBasic Information:\")\n",
    "        print(f\"- Total Rows: {len(self.df)}\")\n",
    "        print(f\"- Total Columns: {len(self.df.columns)}\")\n",
    "        print(f\"- Numeric Columns: {len(self.numeric_columns)}\")\n",
    "        print(f\"- Non-numeric Columns: {len(self.df.columns) - len(self.numeric_columns)}\")\n",
    "        \n",
    "        print(\"\\nNumeric Columns Summary:\")\n",
    "        print(self.df[self.numeric_columns].describe())\n",
    "        \n",
    "        print(\"\\nMissing Values Summary:\")\n",
    "        self.check_missing_values()\n",
    "        \n",
    "        # Generate and save all plots\n",
    "        self.plot_distributions()\n",
    "        plt.savefig('distributions.png')\n",
    "        \n",
    "        self.correlation_analysis()\n",
    "        plt.savefig('correlation.png')\n",
    "        \n",
    "        self.plot_outliers()\n",
    "        plt.savefig('outliers.png')\n",
    "        \n",
    "        print(\"\\nPlots have been saved as:\")\n",
    "        print(\"- distributions.png\")\n",
    "        print(\"- correlation.png\")\n",
    "        print(\"- outliers.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage Example:\n",
    "\"\"\"\n",
    "# Initialize the class with a DataFrame\n",
    "eda = UniversalEDA(df)\n",
    "\n",
    "# Generate comprehensive summary report\n",
    "eda.generate_summary_report()\n",
    "\n",
    "# Or perform specific analyses\n",
    "eda.plot_distributions()  # Check distributions\n",
    "eda.check_missing_values()  # Analyze missing values\n",
    "eda.correlation_analysis()  # Analyze correlations\n",
    "eda.plot_outliers()  # Visualize outliers\n",
    "\n",
    "# Normalize data\n",
    "normalized_df, scalers = eda.normalize_data()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro, spearmanr, pearsonr\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "# 1. Plot distribution of numerical features\n",
    "def plot_distribution(df):\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in num_cols:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.histplot(df[col], kde=True, bins=30, color='blue')\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "\n",
    "# 2. Missing Value Analysis\n",
    "def missing_value_analysis(df):\n",
    "    missing_counts = df.isnull().sum()\n",
    "    missing_counts = missing_counts[missing_counts > 0]\n",
    "    print(\"Missing Values Per Column:\")\n",
    "    print(missing_counts)\n",
    "    \n",
    "    if missing_counts.sum() > 0:\n",
    "        print(\"\\nRows with Missing Values:\")\n",
    "        display(df[df.isnull().any(axis=1)])\n",
    "\n",
    "# 3. Compute Correlation (Pearson if normal, Spearman otherwise)\n",
    "def calculate_correlation(df):\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    correlation_matrix = pd.DataFrame(index=num_cols, columns=num_cols)\n",
    "    \n",
    "    for col1 in num_cols:\n",
    "        for col2 in num_cols:\n",
    "            if col1 != col2:\n",
    "                stat, p = shapiro(df[col1].dropna())\n",
    "                if p > 0.05:  # Normally distributed\n",
    "                    corr, _ = pearsonr(df[col1].dropna(), df[col2].dropna())\n",
    "                else:  # Not normally distributed\n",
    "                    corr, _ = spearmanr(df[col1].dropna(), df[col2].dropna())\n",
    "                correlation_matrix.loc[col1, col2] = corr\n",
    "    \n",
    "    correlation_matrix = correlation_matrix.astype(float)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title(\"Correlation Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    return correlation_matrix\n",
    "\n",
    "# 4. Detect Outliers\n",
    "def detect_outliers(df, method=\"zscore\", threshold=3):\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    outlier_dict = {}\n",
    "    \n",
    "    for col in num_cols:\n",
    "        if method == \"zscore\":\n",
    "            mean, std = df[col].mean(), df[col].std()\n",
    "            z_scores = (df[col] - mean) / std\n",
    "            outliers = df[np.abs(z_scores) > threshold]\n",
    "        elif method == \"iqr\":\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            outliers = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))]\n",
    "        \n",
    "        if not outliers.empty:\n",
    "            outlier_dict[col] = outliers\n",
    "    \n",
    "    return outlier_dict\n",
    "\n",
    "# 5. Normalize Data\n",
    "def normalize_data(df):\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    scaler_dict = {}\n",
    "    df_scaled = df.copy()\n",
    "    \n",
    "    for col in num_cols:\n",
    "        outliers = detect_outliers(df[[col]], method=\"zscore\", threshold=3)\n",
    "        \n",
    "        if len(outliers) > 0:\n",
    "            scaler = RobustScaler()\n",
    "            print(f\"Using RobustScaler for {col} (outliers detected)\")\n",
    "        else:\n",
    "            scaler = StandardScaler()\n",
    "            print(f\"Using StandardScaler for {col} (no outliers detected)\")\n",
    "        \n",
    "        df_scaled[col] = scaler.fit_transform(df[[col]])\n",
    "        scaler_dict[col] = scaler\n",
    "    \n",
    "    return df_scaled, scaler_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
